# PADAI: Psychological Abuse Detection AI
> **Where Generative AI meets gender-based violence prevention.**  
> *Using state-of-the-art language models to uncover hidden psychological abuse in everyday messages.*

## Mission & Social Context

Psychological abuse often hides in plain sight within everyday communication. In messages between former partners, words that appear caring or casual can mask manipulative, controlling, or degrading intent. Unlike explicit slurs or threats, these implicit forms of abuse are harder to recognize but can be just as damaging—eroding a survivor’s self-esteem and well-being over time while leaving little tangible evidence. Detecting this hidden abuse matters because it validates survivors’ experiences, provides crucial context for legal or counseling support, and shines a light on a form of gender-based violence that frequently goes unaddressed.

PADAI (Psychological Abuse Detection AI) is dedicated to tackling this challenge by uncovering subtle signals of emotional abuse in text. It leverages state-of-the-art language models trained on a unique corpus of real, anonymized messages from women who have experienced psychological abuse, ensuring the AI learns from genuine patterns of manipulation and gaslighting found in real life. In practical terms, PADAI can serve as an early-warning and evidence-gathering tool: it might flag harmful patterns in a survivor’s chat history, help lawyers and advocates identify abusive content for legal cases, or assist counselors in understanding the dynamics at play in a survivor’s story. By bringing these hidden patterns to light, the system empowers those affected and those supporting them to intervene earlier and more effectively.

For the long term, PADAI is also a platform for research across disciplines. Its development and dataset open new avenues—from computational social science studies on how abuse manifests in communication, to improving how AI language models grasp nuanced human behavior, to examining the ethics of deploying AI in sensitive, high-stakes contexts. The project is designed to be accessible and impactful for a broad community—from legal professionals, NGOs, and journalists documenting abuse, to survivors seeking validation, to researchers in technology and ethics. By bridging cutting-edge AI with lived experiences, PADAI offers a responsible, purpose-driven approach to technology for social good.